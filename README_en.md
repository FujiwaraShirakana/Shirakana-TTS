## Note: TTS & SVS Support：[MoeVoiceStudio](https://github.com/NaruseMioShirakana/MoeVoiceStudio/tree/MoeVoiceStudio) [MoeVoiceStudioCore](https://github.com/NaruseMioShirakana/MoeVoiceStudio/tree/MoeVoiceStudioCore).

# MoeVoiceStudio
| [Chinese](README.md) | [English](README_en.md)

This project is a voice assistant software focused on the Otaku subculture and targeted at anime fans.

<details><summary><b>Supported Frameworks:</b></summary>
    
- [DeepLearningExamples](https://github.com/NVIDIA/DeepLearningExamples)
- [VITS](https://github.com/jaywalnut310/vits)
- [SoVits](https://github.com/svc-develop-team/so-vits-svc)
- [DiffSvc](https://github.com/prophesier/diff-SVC)
- [DiffSinger](https://github.com/openvpi/DiffSinger)
- [RVC](https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI)
- [FishDiffusion](https://github.com/fishaudio/fish-diffusion)
    
</details>

## Contents
- [User Agreement](#user-agreement)
  - [Disclaimer](#disclaimer) 
- [Description](#description)
  - [Branches](#branches)
- [FAQ](#faq)
  - Q: [What is the purpose of this project?](#q-what-is-the-purpose-of-this-project)
  - Q: [Will this project charge fees in the future?](#q-will-this-project-be-charged-in-the-future)
  - Q: [Do you provide paid model training?](#q-do-you-provide-paid-model-training)
  - Q: [What are the criteria for digital garbage?](#q-what-are-the-criteria-for-digital-garbage)
  - Q: [Technical support?](#q-technical-support)
- [Notes](#notes)
- [Usage](#usage)
- [Model Configuration](#model-configuration)
  - [Pre-models](#pre-models) 
  - [Configuration File](#configuration-file)
- [Supported Projects](#supported-projects)
- [Other Settings](#other-settings)
  - [Symbol](#symbol)
  - [Cleaner](#cleaner)
- [Build](#build)
- [List of dependencies](#list-of-dependencies)
- [Relevant Regulations](#relevant-regulations)

## User Agreement:
### To use this project, you must agree to the following terms. If you do not agree, you are prohibited from using this project:
1. You must bear all the consequences caused by using this project.
2. It is forbidden to sell this program.
3. When using this project, you must conscientiously abide by local laws and regulations, and it is forbidden to use this project for illegal activities.
4. It is forbidden to use for any commercial games, low-creation games[^1], and Galgame production, but non-commercial high-quality game and Mod production are acceptable.
5. It is forbidden to use this project and its derivatives, and the release of models, etc., to produce various electronic wastes[^2] (such as AIGalgame, AI game production, etc.).
6. All political-related content is prohibited.
7. All content generated by using this project has nothing to do with the developers of this project.


[^1]: The criteria for low creativity are: any content generated in large amounts by AI, with low original content, unclear meaning, low quality of content, etc.

[^2]: Criteria for digital garbage are: Originality. The proportion of your own work in the entire project (for AI, creations using models trained completely independently by you belong to you; creations using others' models belong to others). Aspects covered include but are not limited to programming, art, audio, planning, etc. For example, reskinning using templates from engines like Unity is considered digital garbage.

## Disclaimer
This project is an **open-source, offline project. All developers and maintainers (hereinafter referred to as contributors) of this project have no control over it**. The contributors to this project have never provided any form of help to any organization or individual, including but not limited to data set extraction, data set processing, computational power support, training support, inference, etc. The contributors of this project are unaware and cannot be aware of the purpose of the user's use of the project. Therefore, all audio synthesized based on this project is unrelated to the contributors of this project. **Any problems arising from this will be borne by the users themselves**.

This project itself does not have any speech synthesis capabilities, all functions need to be trained by the user themselves and convert into Onnx models, and the training of the model and Converted Onnx models are unrelated to the contributors of this project, all are the actions of the user themselves, and the contributors of this project have not participated in any user's model training and production.

This project runs completely offline, it cannot collect any user information, nor can it get user input data, so the contributors of this project are unaware of all user input and the model, and therefore are not responsible for any user input.

**This project does not come with any models, any models attached to any secondary release and models used for this project are unrelated to the developers of this project.**

## Description
This project currently fully supports calling its own methods to achieve command-line inference or other software, and everyone is welcome to contribute PRs to this project.

The author's other projects: [AiToolKits](https://github.com/NaruseMioShirakana/ShirakanaNoAiToolKits)

If you want to participate in development, you can join QQ group: 263805400 or directly open Push Requests.

**Models need to be converted into ONNX models, the program for converting ONNX has already been pulled to each project's source repository, PTH cannot be used directly!!!!!!!!!!!!!!!!!!!**

## Branches
The branches of this project:
- [MoeVoiceStudioCore(main branch)](https://github.com/NaruseMioShirakana/MoeVoiceStudio/tree/MoeVoiceStudioCore) Project core
- [MoeVoiceStudio](https://github.com/NaruseMioShirakana/MoeVoiceStudio/tree/MoeVoiceStudio) A simple GUI implementation of this project based on QT
- [MoeSSV2](https://github.com/NaruseMioShirakana/MoeVoiceStudio/tree/V2) Old version of MoeSS V2 version archive
- [MoeSSV1](https://github.com/NaruseMioShirakana/MoeVoiceStudio/tree/V1) Old version of MoeSS V1 version archive

## FAQ
### Q: What is the purpose of this project?
<details><summary>A: </b></summary>

> The original intention of this project's development is mainly to implement various speech synthesis projects without the need for environment deployment, and now it is planned to be made into an auxiliary editor of SVC. Because this project is after all a "personal" "non-professional" project, so if you have more professional software, or you are a Python Cli lover, or you are a big shot in the relevant field. I know that this software is not professional enough and is very likely to be unable to meet your needs or even useless to you. This project is not an irreplaceable project, on the contrary, you can use various tools to replace the functions of this project, I have no extravagant hopes that this project will become a leading project in the relevant field, I am just continuing the development of this project with enthusiasm. But passion always has a day to dissipate, but the project promises to keep maintenance as long as my development passion has not completely dissipated (regardless of whether there are any users, even if the number of users is 0).
> 
> There may be various problems in the design of this project, so we also need everyone to actively point out to help me improve the functionality. Most optimizations for functionality and experience I will accept.
> 
> Finally, let me say one more thing about my view of this project: MoeSS and MoeVS are relying on the defense.

</details>

### Q: Will this project be charged in the future?
<details><summary>A: </b></summary>

> This project will remain open-source and free forever, if there are paid versions of this project elsewhere, please report immediately and do not purchase, this project is always free. If you want to donate the developer, you can go to Shirakana's Afdian site: https://afdian.net/a/NaruseMioShirakana .

</details>

### Q: Do you provide paid model training?
<details><summary>A: </b></summary>

> No, training models is relatively simple, there is no need to waste money, just follow the online tutorials step by step. 

</details>

### Q: What are the criteria for digital garbage?
<details><summary>A: </b></summary>

> Originality. Your own work's proportion in the entire project (for AI, creations using completely independently trained models by you belong to you; creations using models from others belong to others). This includes but is not limited to programming, art, audio, planning, etc. For example, reskinning using templates from engines like Unity is considered digital garbage.
Developer's attitude. Whether the author's development attitude is to gain traffic and money and leave, or purely vanity. For example, using a lot of tags like "domestic", "first", "strongest", "homemade" for traffic attraction, but the result is very bad or mediocre work, and the author obviously does not have a good idea to make the project, this is considered digital garbage.
We oppose all commercial use of AI models trained using unauthorized datasets.

</details>

### Q: Technical support?
<details><summary>A: </b></summary>

> If I can confirm that what you're doing is not digital garbage, is legal and compliant, and does not have serious political errors, I will provide some technical support within my capacity.

</details>

## Notes
### Due to issues raised by OnnxRuntime
For using GPU (CUDA) version, please install CUDA driver version between 11.0 and 12.0, and CUDNN dynamic library version below 83.0, following the tutorials available online.

Why such requirements? That would be a question for NVIDIA, the company behind CUDA, CUDNN, and the OnnxRuntime officials. Both issues are caused by certain features of CUDA driver and problems with OnnxRuntime.

What's the reason for the previous versions not supporting Chinese paths? Actually, it's just a manifestation of the above issue. The project itself supports Chinese paths, but its underlying OnnxRuntime doesn't, because the Windows version of OnnxRuntime uses the A series functions of Win32Api, and the A series functions do not support paths with non-ANSI encoding. This issue is not something I can solve, nor should I. Only when the OnnxRuntime officials fix this bug can it be resolved. Fortunately, the latest OnnxRuntime uses W series functions, solving this problem with Chinese paths.

Errors popping up when loading the model are caused by the above issues (mainly due to not installing CUDA and CUDNN or not installing them as required). If these issues are triggered, you can go to the Onnx official repository's Issue page at https://github.com/microsoft/onnxruntime to find solutions.

It's recommended to use the CPU version, as its inference speed is quite impressive and it doesn't have other problems.

## Usage
MoeVoiceStudioCore is provided as a library, to be called with C++.

Refer to the following corresponding classes as needed:
```cpp
#include <Modules/Models/header/Tacotron.hpp>
#include <Modules/Models/header/Vits.hpp>
#include <Modules/Models/header/VitsSvc.hpp>
#include <Modules/Models/header/DiffSvc.hpp>
#include <Modules/Models/header/DiffSinger.hpp>

InferClass::Tacotron2;
InferClass::Vits;
InferClass::VitsSvc;
InferClass::DiffusionSvc;
InferClass::DiffusionSinger;

/*
The first parameter of the constructor is the JSON configuration file,
the second one is a callback for the progress bar,
the third one is a callback for parameters (if for TTS, this can be left empty),
and the fourth one is the device.
You can call the Inference function to use it.
*/
```
For model configuration, please refer to [#Model Configuration](#Model Configuration)

Demo: [RVC command-line example](https://github.com/NaruseMioShirakana/MoeVoiceStudio/tree/MoeVoiceStudioCore/CMD-RVC-Onnx-Inference)

## Model Configuration
### Pre-models
#### Not related to the few projects we support, they are universal models in the deep learning domain
Stopped updating (due to download and upload speeds): [Vocoder & HiddenUnitBert](https://github.com/NaruseMioShirakana/RequireMent-Model-For-MoeSS) 

Latest repository: [HuggingFace](https://huggingface.co/NaruseMioShirakana/MoeSS-SUBModel) 

Export frontend yourself:
- HuBert: `input_names` should be `["source"]`, `output_names` should be `["embed"]`, `dynamic_axes` should be `{"
source":[0,2],}`
- Hifigan used by the Diffusion model: `input_names` should be `["c","f0"]`, `output_names` should be `["audio"]`, `dynamic_axes` should be `{"c":[0,1],"f0":[0,1],}`
- Hifigan used by Tacotron2: `input_names` should be `["x"]`, `output_names` should be `["audio"]`, `dynamic_axes` should be `{"x":[0,1],}`

## Configuration File
- This project has standardized the model loading module, the models are saved in subfolders under the Mods folder. `xxx.json` is the configuration file for the model, which needs to be written manually according to the template, and the model needs to be converted to Onnx manually.

#### Universal Parameters (These are mandatory for any model. If not filled, it won't be recognized):
- `Folder`: The folder name where the model is stored
- `Name`: The display name of the model in UI
- `Type`: The category of the model
- `Rate`: Sample rate (it must be exactly the same as when you trained, if you don't understand why, you are recommended to learn about computer audio related knowledge)

### Examples
Notice: `Diff-SVC` model and `Diffusion-SVC` model are basically **NOT** the same model, and the same applies to the `Fish-Diffusion` model, though all of them are based on the Diffusion algorithm.

<details><summary>Tacotron2:</summary>

```jsonc
{
    "Folder" : "Atri",
    "Name" : "ATRI-Tacotron2",
    "Type" : "Tacotron2",
    "Rate" : 22050,
    "Symbol" : "_-!'(),.:;? ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz",
    "Cleaner" : "",
    "AddBlank": false,
    "Hifigan": "hifigan"
}
//Symbol:Symbol of the model,If you don't know what it is, you are advised to check the TTS information on the internet.This field must be filled in the Tacotron2 model's configuration file.
//Cleaner:The name of the plugin,can be left blank, but if it is filled in, the corresponding CleanerDll must be placed in the Cleaner folder, if the Dll does not exist or if there is an internal error in the Dll, it will report an error when loading the model
//Hifigan:Hifigan model name, required and must be placed in the "hifigan" folder for hifigan model downloaded from the Pre-model repository
//AddBlank:Whether to insert a 0 as a separator between phonemes
```
</details>
<details><summary>Vits:</summary>
    
```jsonc
{
    "Folder" : "SummerPockets",
    "Name" : "SummerPocketsReflectionBlue",
    "Type" : "Vits",
    "Rate" : 22050,
    "Symbol" : "_,.!?-~…AEINOQUabdefghijkmnoprstuvwyzʃʧʦ↓↑ ",
    "Cleaner" : "",
    "AddBlank": true,
    "Emotional" : true,
    "EmotionalPath" : "all_emotions",
    "Characters" : ["鳴瀬しろは","空門蒼","鷹原うみ","紬ヴェンダース","神山識","水織静久","野村美希","久島鴎","岬鏡子"]
}
//Symbol:Symbol of the model,If you don't know what it is, you are advised to check the TTS information on the internet.This field must be filled in the VITS model's configuration file.
//Cleaner:The name of the plugin,can be left blank, but if it is filled in, the corresponding CleanerDll must be placed in the Cleaner folder, if the Dll does not exist or if there is an internal error in the Dll, it will report an error when loading the model
//Characters:For multi-speaker model this must be filled in as a list of your speakers' names, for single-speaker model it can be left out
//AddBlank:Whether to insert a 0 as a separator between phonemes（For most VITS models, you must set this to "true"..）
//Emotional:whether to add a emotional vector
//EmotionalPath:emotional vector file(.npy) path
```
</details>
<details><summary>Pits:</summary>

```jsonc
{
    "Folder" : "SummerPockets",
    "Name" : "SummerPocketsReflectionBlue",
    "Type" : "Pits",
    "Rate" : 22050,
    "Symbol" : "_,.!?-~…AEINOQUabdefghijkmnoprstuvwyzʃʧʦ↓↑ ",
    "Cleaner" : "",
    "AddBlank": true,
    "Emotional" : true,
    "EmotionalPath" : "all_emotions",
    "Characters" : ["鳴瀬しろは","空門蒼","鷹原うみ","紬ヴェンダース","神山識","水織静久","野村美希","久島鴎","岬鏡子"]
}
//Symbol:Symbol of the model,If you don't know what it is, you are advised to check the TTS information on the internet.This field must be filled in the VITS model's configuration file.
//Cleaner:The name of the plugin, can be left blank, but if it is filled in, the corresponding CleanerDll must be placed in the Cleaner folder, if the Dll does not exist or if there is an internal error in the Dll, it will report an error when loading the model
//Characters:For multi-speaker model this must be filled in as a list of your speakers' names, for single-speaker model it can be left out
//AddBlank:Whether to insert a 0 as a separator between phonemes（For most VITS models, you must set this to "true"..）
//Emotional:whether to add a emotional vector
//EmotionalPath:emotional vector file(.npy) path
```
    
</details>
<details><summary>RVC:</summary>
    
```jsonc
{
    "Folder" : "NyaruTaffy",
    "Name" : "NyaruTaffy",
    "Type" : "RVC",
    "Rate" : 40000,
    "Hop" : 320,
    "Cleaner" : "",
    "Hubert": "hubert4.0",
    "Diffusion": false,
    "CharaMix": true,
    "Volume": false,
    "HiddenSize": 256,
    "Characters" : ["Taffy","Nyaru"]
}
//Hop:HopLength of the model, if you don't know what it is you are advised to look up the information on the internet. This must be filled in the configuration file of the SoVits model.（The value must be the one you set during training and can be seen in the configuration file you used to train the model）
//Cleaner:The name of the plugin,can be left blank, but if it is filled in, the corresponding CleanerDll must be placed in the Cleaner folder, if the Dll does not exist or if there is an internal error in the Dll, it will report an error when loading the model
//Hubert:Hubert model name, required and must be placed in the "Hubert" folder for Hubert model downloaded from the Pre-model repository
//Characters:For multi-speaker model this must be filled in as a list of your speakers' names, for single-speaker model it can be left out
//Diffusion:if this diffusion model is trained by DDSP-SVC (Diffusion-SVC) , set this to "true".
//CharaMix:whether or not to use the character mixing track
//Volume:whether the model have volume Embedding, if it has, set this to "true".
//HiddenSize:Size of the Vec model(256/768)
```
</details>
<details><summary>SoVits_3.0_32k:</summary>

```jsonc
{
    "Folder" : "NyaruTaffySo",
    "Name" : "NyaruTaffy-SoVits",
    "Type" : "SoVits",
    "Rate" : 32000,
    "Hop" : 320,
    "Cleaner" : "",
    "Hubert": "hubert",
    "SoVits3": true,
    "Diffusion": false,
    "CharaMix": true,
    "Volume": false,
    "HiddenSize": 256,
    "Characters" : ["Taffy","Nyaru"]
}
//Hop:HopLength of the model, if you don't know what it is you are advised to look up the information on the internet. This must be filled in the configuration file of the SoVits model.（The value must be the one you set during training and can be seen in the configuration file you used to train the model）
//Cleaner:The name of the plugin,can be left blank, but if it is filled in, the corresponding CleanerDll must be placed in the Cleaner folder, if the Dll does not exist or if there is an internal error in the Dll, it will report an error when loading the model
//Hubert:Hubert model name, required and must be placed in the "Hubert" folder for Hubert model downloaded from the Pre-model repository
//Characters:For multi-speaker model this must be filled in as a list of your speakers' names, for single-speaker model it can be left out
//Diffusion:if this diffusion model is trained by DDSP-SVC (Diffusion-SVC) , set this to "true".
//CharaMix:whether or not to use the character mixing track
//Volume:whether the model have volume Embedding, if it has, set this to "true".
//HiddenSize:Size of the Vec model(256/768)
```
    
</details>
<details><summary>SoVits_3.0_48k:</summary>

```jsonc
{
    "Folder" : "NyaruTaffySo",
    "Name" : "NyaruTaffy-SoVits",
    "Type" : "SoVits",
    "Rate" : 48000,
    "Hop" : 320,
    "Cleaner" : "",
    "Hubert": "hubert",
    "SoVits3": true,
    "Diffusion": false,
    "CharaMix": true,
    "Volume": false,
    "HiddenSize": 256,
    "Characters" : ["Taffy","Nyaru"]
}
//Hop:HopLength of the model, if you don't know what it is you are advised to look up the information on the internet. This must be filled in the configuration file of the SoVits model.（The value must be the one you set during training and can be seen in the configuration file you used to train the model）
//Cleaner:The name of the plugin,can be left blank, but if it is filled in, the corresponding CleanerDll must be placed in the Cleaner folder, if the Dll does not exist or if there is an internal error in the Dll, it will report an error when loading the model
//Hubert:Hubert model name, required and must be placed in the "Hubert" folder for Hubert model downloaded from the Pre-model repository
//Characters:For multi-speaker model this must be filled in as a list of your speakers' names, for single-speaker model it can be left out
//Diffusion:if this diffusion model is trained by DDSP-SVC (Diffusion-SVC) , set this to "true".
//CharaMix:whether or not to use the character mixing track
//Volume:whether the model have volume Embedding, if it has, set this to "true".
//HiddenSize:Size of the Vec model(256/768)
```
    
</details>
<details><summary>SoVits_4.0:</summary>
    
```jsonc
{
    "Folder" : "NyaruTaffySo",
    "Name" : "NyaruTaffy-SoVits",
    "Type" : "SoVits",
    "Rate" : 44100,
    "Hop" : 512,
    "Cleaner" : "",
    "Hubert": "hubert4.0",
    "SoVits4": true,
    "Diffusion": false,
    "CharaMix": true,
    "Volume": false,
    "HiddenSize": 256,
    "Characters" : ["Taffy","Nyaru"]
}
//Hop:HopLength of the model, if you don't know what it is you are advised to look up the information on the internet. This must be filled in the configuration file of the SoVits model.（The value must be the one you set during training and can be seen in the configuration file you used to train the model）
//Cleaner:The name of the plugin,can be left blank, but if it is filled in, the corresponding CleanerDll must be placed in the Cleaner folder, if the Dll does not exist or if there is an internal error in the Dll, it will report an error when loading the model
//Hubert:Hubert model name, required and must be placed in the "Hubert" folder for Hubert model downloaded from the Pre-model repository
//Characters:For multi-speaker model this must be filled in as a list of your speakers' names, for single-speaker model it can be left out
//Diffusion:if this diffusion model is trained by DDSP-SVC (Diffusion-SVC) , set this to "true".
//CharaMix:whether or not to use the character mixing track
//Volume:whether the model have volume Embedding, if it has, set this to "true".
//HiddenSize:Size of the Vec model(256/768)
```
    
</details>
<details><summary>DiffSVC:</summary>
    
```jsonc
{
    "Folder" : "DiffShiroha",
    "Name" : "白羽",
    "Type" : "DiffSvc",
    "Rate" : 44100,
    "Hop" : 512,
    "MelBins" : 128,
    "Cleaner" : "",
    "Hifigan": "nsf_hifigan",
    "Hubert": "hubert",
    "Characters" : [],
    "Pndm" : 100,
    "Diffusion": false,
    "CharaMix": true,
    "Volume": false,
    "HiddenSize": 256,
    "V2" : true
}
//Hop:HopLength of the model, if you don't know what it is you are advised to look up the information on the internet. This must be filled in the configuration file of the SoVits model.（The value must be the one you set during training and can be seen in the configuration file you used to train the model）
//Melbins:Melbins of the model, if you don't know what it is you are advised to look up the information on the internet. This must be filled in the configuration file of the Diffsvc model.（The value must be the one you set during training and can be seen in the configuration file you used to train the model）
//Cleaner:The name of the plugin,can be left blank, but if it is filled in, the corresponding CleanerDll must be placed in the Cleaner folder, if the Dll does not exist or if there is an internal error in the Dll, it will report an error when loading the model
//Hubert:Hubert model name, required and must be placed in the "Hubert" folder for Hubert models downloaded from the Pre-model repository
//Hifigan:Hifigan model name, required and must be placed in the "hifigan" folder for nsf-hifigan model downloaded from the Pre-model repository
//Characters:For multi-speaker model this must be filled in as a list of your speakers' names, for single-speaker model it can be left out
//Pndm:Acceleration multiplier, required in the case of V1 models and must be the acceleration multiplier set at the time of export
//V2:If your diffsvc model is a V2 model(Fish-Diffusion model), set this to "true".
//Diffusion:if this diffusion model is trained by DDSP-SVC (Diffusion-SVC) , set this to "true".
//CharaMix:whether or not to use the character mixing track
//Volume:whether the model have volume Embedding, if it has, set this to "true".
//HiddenSize:Size of the Vec model(256/768)
```
    
</details>
<details><summary>DiffSinger:</summary>
    
```jsonc
{
    "Folder" : "utagoe",
    "Name" : "utagoe",
    "Type" : "DiffSinger",
    "Rate" : 44100,
    "Hop" : 512,
    "Cleaner" : "",
    "Hifigan": "singer_nsf_hifigan",
    "Characters" : [],
    "MelBins" : 128
}
```jsonc
{
    "Folder" : "utagoe",
    "Name" : "utagoe",
    "Type" : "DiffSinger",
    "Rate" : 44100,
    "Hop" : 512,
    "Cleaner" : "",
    "Hifigan": "singer_nsf_hifigan",
    "Characters" : [],
    "MelBins" : 128
}
//Hop:HopLength of the model, if you don't know what it is you are advised to look up the information on the internet. This must be filled in the configuration file of the Diffsinger model.（The value must be the one you set during training and can be seen in the configuration file you used to train the model）
//Melbins:Melbins of the model, if you don't know what it is you are advised to look up the information on the internet. This must be filled in the configuration file of the Diffsvc model.（The value must be the one you set during training and can be seen in the configuration file you used to train the model）
//Cleaner:The name of the plugin,can be left blank, but if it is filled in, the corresponding CleanerDll must be placed in the Cleaner folder, if the Dll does not exist or if there is an internal error in the Dll, it will report an error when loading the model
//Hifigan:Hifigan model name, required and must be placed in the "hifigan" folder for nsf-hifigan model downloaded from the Pre-model repository
//Characters:For multi-speaker model this must be filled in as a list of your speakers' names, for single-speaker model it can be left out
```
    
</details>

## Supported Projects

```cxx 
// $Below are the model files needed for several different projects (they need to be placed in the corresponding model folders).
// Tacotron2:
    ${Folder}_decoder_iter.onnx
    ${Folder}_encoder.onnx
    ${Folder}_postnet.onnx
// Vits:    Single-speaker VITS
    ${Folder}_dec.onnx
    ${Folder}_flow.onnx
    ${Folder}_enc_p.onnx
    ${Folder}_dp.onnx 
// Vits:   multi-speaker VITS
    ${Folder}_dec.onnx
    ${Folder}_emb.onnx
    ${Folder}_flow.onnx
    ${Folder}_enc_p.onnx
    ${Folder}_dp.onnx
// SoVits:
    ${Folder}_SoVits.onnx
// DiffSvc:
    ${Folder}_diffSvc.onnx
// DiffSvc: V2
    ${Folder}_encoder.onnx
    ${Folder}_denoise.onnx
    ${Folder}_pred.onnx
    ${Folder}_after.onnx
// DiffSinger: OpenVpiVersion
    ${Folder}_diffSinger.onnx
// DiffSinger: 
    ${Folder}_encoder.onnx
    ${Folder}_denoise.onnx
    ${Folder}_pred.onnx
    ${Folder}_after.onnx
```
## Other Settings
### Symbol settings
    For example：_-!'(),.:;? ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz
    Open the project you are using to train the model, open text\symbol.py and join the 4 strings above in the order of the underlined list as shown
![image](https://user-images.githubusercontent.com/40709280/183290732-dcb93323-1061-431b-aafa-c285a3ec5e82.png)

### Cleaner settings
```cxx
/*
The Cleaner should be placed in the Cleaners folder in the root directory and should be a dynamic library (.dll) defined as required. The dll should be named Cleaner and the Cleaner name is what is entered in the "Cleaner" of the model configuration file.
The following functions need to be defined for all plug-in dlls, the function name must be PluginMain and the Dll name must be the plug-in name (or Cleaner name).
*/
const wchar_t* PluginMain(const wchar_t*);
// The interface only requires consistent input and output, not consistent functionality, which means that you can implement any functionality you want in the Dll, such as ChatGpt, translation, etc.
// Using ChatGpt as an example, the PluginMain function passes in an input string input, passes that input into ChatGpt, passes ChatGpt's output into PluginMain, and finally returns the output.
wchar_t* PluginMain(wchar_t* input){
    wchar_t* tmpOutput = ChatGpt(input);
    return Clean(tmpOutput);
}
// Note: Please use the extern "C" keyword when exporting the dll to prevent destructive naming in C++.
```

## Build
```cxx
git clone https://github.com/NaruseMioShirakana/MoeVoiceStudio.git
cd MoeVoiceStudio
mkdir build
cd build
cmake ../
make .
```

## List of dependencies
- [FFmpeg](https://ffmpeg.org/)
- [World](https://github.com/JeremyCCHsu/Python-Wrapper-for-World-Vocoder)
- [rapidJson](https://github.com/Tencent/rapidjson)

## 📚 相关法规

#### Any country, region, organization, or individual using this project must comply with the following laws.

#### 《民法典》

##### 第一千零一十九条 

任何组织或者个人不得以丑化、污损，或者利用信息技术手段伪造等方式侵害他人的肖像权。未经肖像权人同意，不得制作、使用、公开肖像权人的肖像，但是法律另有规定的除外。
未经肖像权人同意，肖像作品权利人不得以发表、复制、发行、出租、展览等方式使用或者公开肖像权人的肖像。
对自然人声音的保护，参照适用肖像权保护的有关规定。

#####  第一千零二十四条 

【名誉权】民事主体享有名誉权。任何组织或者个人不得以侮辱、诽谤等方式侵害他人的名誉权。  

#####  第一千零二十七条

【作品侵害名誉权】行为人发表的文学、艺术作品以真人真事或者特定人为描述对象，含有侮辱、诽谤内容，侵害他人名誉权的，受害人有权依法请求该行为人承担民事责任。
行为人发表的文学、艺术作品不以特定人为描述对象，仅其中的情节与该特定人的情况相似的，不承担民事责任。  

#### 《[中华人民共和国宪法](http://www.gov.cn/guoqing/2018-03/22/content_5276318.htm)》

#### 《[中华人民共和国刑法](http://gongbao.court.gov.cn/Details/f8e30d0689b23f57bfc782d21035c3.html?sw=%E4%B8%AD%E5%8D%8E%E4%BA%BA%E6%B0%91%E5%85%B1%E5%92%8C%E5%9B%BD%E5%88%91%E6%B3%95)》

#### 《[中华人民共和国民法典](http://gongbao.court.gov.cn/Details/51eb6750b8361f79be8f90d09bc202.html)》

#

The image resource MoeVS used is derived from：
- [SummerPockets](http://key.visualarts.gr.jp/summer/)

## 💪 Thanks to all contributors for their efforts
<a href="https://github.com/NaruseMioShirakana/MoeSS/graphs/contributors" target="_blank">
  <img src="https://contrib.rocks/image?repo=NaruseMioShirakana/MoeSS" />
</a>
